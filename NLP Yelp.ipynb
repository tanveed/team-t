{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Yelp Review to Rating\n",
    "### Authors: Tanvee Desai and Tanner Arrizabalaga\n",
    "\n",
    "Hello! In this project, we will be looking over Yelp reviews (data available here: https://www.yelp.com/dataset) and utilizing ML/DL to accurately predict what the reviews star rating is based solely on text.\n",
    "\n",
    "This project is split into the following parts\n",
    "- Libraries\n",
    "- EDA\n",
    "- Data Cleaning\n",
    "    - Stop word removal, HTML parsing, punctuation removal, etc.\n",
    "    - Creation of a cleaned *and* stemmed dataset\n",
    "- Model Implementation\n",
    "    - Simple BOW Model Neural Network\n",
    "    - LSTM\n",
    "    - One vs. All LSTM Approach\n",
    "- Exploring Challenges\n",
    "    - Challenge 5\n",
    "    - Challenge 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# ML/DL\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM, BatchNormalization, SpatialDropout1D, Bidirectional\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras import regularizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_json(\"./yelp_review_training_dataset.jsonl\", lines = True)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - Stars\n",
    "Not too much to go off of, but let's get a general understanding of our data. How many nulls do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(yelp['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can potentially look at is whether or not the reviews are balanced. Let's say >=4 is positive, and <4 is negative. If we do see a significant difference in positive and negative reviews, we can balance it before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg(x):\n",
    "    if x >= 4:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "    \n",
    "yelp['category'] = yelp['stars'].apply(pos_or_neg)\n",
    "\n",
    "sns.countplot(yelp['category'])\n",
    "num_pos = np.count_nonzero(yelp['category'] == 'Positive')\n",
    "num_neg = np.count_nonzero(yelp['category'] == 'Negative')\n",
    "print(\"Positive to negative review ratio: \", num_pos / num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 1 and 2/3 times as many positive reviews as negative reviews. We will first try no class balancing when building the model, but may turn to class balancing later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you'll\", 'only', 'over', 'or', 'to', \"couldn't\", 'off', 'do', 'this', 'against', 'between', 'above', 'same', 'most', \"isn't\", 'weren', \"should've\", 'such', 'should', 're', 'her', 'just', 'not', 'and', 'down', 'nor', 'couldn', 'we', \"mightn't\", 'wouldn', 'again', 'up', 'a', 'the', 'than', 'further', 'she', 'if', 'through', 'ours', \"she's\", \"weren't\", 'each', 'needn', \"doesn't\", 'am', 'after', 'on', 'himself', 'was', 'of', 'too', \"shouldn't\", 'its', 'mightn', 'it', 'so', 'aren', \"hasn't\", 'some', 'below', \"you're\", \"wouldn't\", 'y', \"haven't\", 'them', 'didn', 'won', 'where', 'wasn', 'me', 'having', 'no', 'from', \"hadn't\", 'out', 'all', 'into', 'hasn', \"aren't\", 'theirs', 'haven', \"wasn't\", 'our', 'herself', 'can', 'but', 'shouldn', 'him', 'has', 'for', 'being', 'itself', 'll', 'i', 'his', 'were', 'hadn', 've', \"needn't\", 'ain', 'here', 'are', 'by', 'with', 'isn', 'more', 'that', 'does', 'yours', 'doing', \"it's\", 'these', 'don', 'now', \"that'll\", 'o', \"you'd\", 'ma', 'doesn', 's', 'had', 'have', 'both', 'there', 'been', \"didn't\", 'shan', 'as', 'yourself', 'when', 'once', 'themselves', 'until', 'while', 'will', 'is', 'before', 'at', 'hers', 'they', 'you', 'during', 'because', \"won't\", 'my', 'yourselves', 'then', 'how', 't', 'ourselves', 'be', 'about', 'did', 'who', 'he', 'under', 'in', 'their', 'those', 'whom', \"mustn't\", 'any', 'why', 'own', 'few', 'other', 'mustn', \"shan't\", 'm', \"don't\", 'myself', 'your', 'which', \"you've\", 'very', 'an', 'd', 'what'}\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "print(STOPWORDS)\n",
    "\n",
    "def adjust_stopwords(stopwords):\n",
    "    words_to_keep = set('nor', 'not', 'very', 'no')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    new_text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    new_text = new_text.lower() # lowercase text\n",
    "    new_text = REPLACE_BY_SPACE_RE.sub(' ', new_text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    new_text = BAD_SYMBOLS_RE.sub(' ', new_text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "   \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    new_text = ' '.join(ps.stem(word) for word in new_text.split()) # keeping all words, no stop word removal\n",
    "#     new_text = ' '.join(ps.stem(word) for word in new_text.split() if word not in STOPWORDS) # delete stopwords from text and stem\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['text'] = yelp['text'].apply(clean_text)\n",
    "yelp.to_csv('cleaned_yelp_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"\\\"Good morning, cocktails for you?\\\" \\nWait...what? Oh...it's Vegas!\\n\\nDining here, you best not be dieting because this place is literally the definition of excess, but in a good way. I'm a sucker for benedicts so that was awesome. \\nService was really great too and the staff was so welcoming. It was our first stop just after landing so really appreciate the service.\\n\\nBack in Hawaii this reminds me of Zippys or Anna Millers - that home feeling. Prices are a bit high, but for what you get it's totally worth it. Will remember this place if I ever return to Vegas in the future.\"\n",
    "text_2 = \"80 bucks, thirty minutes to fix my shattered iPhone screen. Verizon won't help you so go here\"\n",
    "text_3 = \"Tr\\u00e8s grand caf\\u00e9, mais aussi calme et reposant, je m'y suis arr\\u00eat\\u00e9 alors que j'\\u00e9tais dans le coin.\\n\\nOn peu y mang\\u00e9 le midi, prendre une p\\u00e2tisserie ou un caf\\u00e9/th\\u00e9. \\n\\nJ'ai prit un th\\u00e9 qui \\u00e9tait vraiment bon, et je me suis pos\\u00e9 devant une des grandes baies vitr\\u00e9es sur un coussin et j'ai relax\\u00e9 compl\\u00e8tement pendant 2 heures. \\n\\nMais c'est aussi une coop\\u00e9rative d'artiste, avec une estrade etc.\\n\\nIl y a aussi un magasin Bio \\u00e0 l'entr\\u00e9e o\\u00f9 vous retrouverez des savons, huile d'olive et plein d'autres produits.\"\n",
    "text_4 = \"Sadly, as of July 28, 2016, Silverstein bakery is permanently closed. I went there today in person and found the bad news posted on their door. :(\"\n",
    "text_5 = \"I went here  they were about to close but the cashier was especially helpful ..but I guess they were tired of work...\"\n",
    "\n",
    "clean_text(text_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "#### 1. Average Star Error (Average Absolute offset between predicted and true number of stars)\n",
    "#### 2. Accuracy (Exact Match -- Number of exactly predicted star ratings / total samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):\n",
    "    diffs = np.abs(y_true - y_pred)\n",
    "    loss = np.mean(diffs)\n",
    "    return loss\n",
    "\n",
    "def Accuracy(y_true, y_pred):\n",
    "    correct = y_true == y_pred\n",
    "    cor_count = np.count_nonzero(correct)\n",
    "    return cor_count / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (Unbalanced and balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>total bill for thi horribl servic over 8g thes...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>i ador travi at the hard rock s new kelli card...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>i have to say that thi offic realli ha it toge...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>went in for a lunch steak sandwich wa delici a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>today wa my second out of three session i had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id  \\\n",
       "0           0  Q1sbwvVQXV2734tPgoKj4Q   \n",
       "1           1  GJXCdrto3ASJOqKeVWPi6Q   \n",
       "2           2  2TzJjDVDEuAW6MR5Vuc1ug   \n",
       "3           3  yi0R0Ugj_xUx_Nek0-_Qig   \n",
       "4           4  11a8sVPMUFtaC7_ABRkmtw   \n",
       "\n",
       "                                                text  stars  category  \n",
       "0  total bill for thi horribl servic over 8g thes...      1  Negative  \n",
       "1  i ador travi at the hard rock s new kelli card...      5  Positive  \n",
       "2  i have to say that thi offic realli ha it toge...      5  Positive  \n",
       "3  went in for a lunch steak sandwich wa delici a...      5  Positive  \n",
       "4  today wa my second out of three session i had ...      1  Negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = pd.read_csv('cleaned_yelp_stemmed.csv')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp['text'].fillna('').values\n",
    "y = yelp['stars']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 3000\n",
    "tokenizer = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_matrix(X_train)\n",
    "X_test = tokenizer.texts_to_matrix(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the tokenizer as well for our test submission file script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are computing a single model, but in future we will optimize on several parameters, listed below\n",
    "* Batch size\n",
    "* Learning rate\n",
    "* Gradient clipping\n",
    "* Drop out\n",
    "* Batch normalization\n",
    "* Optimizers\n",
    "* Regularization\n",
    "\n",
    "After some tests, the main variations I noticed were from the learning rate, regularization, and the choice of the optimizer. With that being said, this baseline model will use **ADAM with a learning rate of .0001 and regularization (kernel, bias, and activity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 10\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.95, amsgrad=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "          bias_regularizer=regularizers.l2(1e-4),\n",
    "          activity_regularizer=regularizers.l2(1e-5)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/baseline.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now training with several parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [128, 256, 512]\n",
    "epochs = [5]\n",
    "learning_rates = [.01, .001, .0001]\n",
    "dropout = [False, True]\n",
    "batch_norm = [False, True]\n",
    "regularization = [True]\n",
    "optimizers = [\"SGD\", \"RMSProp\", \"ADAM\"]\n",
    "\n",
    "all_lists = [batch_sizes, epochs, learning_rates, dropout, batch_norm, regularization, optimizers]\n",
    "\n",
    "params_to_test = list(itertools.product(*all_lists))\n",
    "print(len(params_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "histories = {}\n",
    "scores = {}\n",
    "\n",
    "for params in params_to_test:\n",
    "    print(params)\n",
    "    batch_size, epochs, learning_rate, dropout, batch_norm, regularization, opt = params\n",
    "    \n",
    "    if opt == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0, nesterov=False)\n",
    "    elif opt == \"RMSProp\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate, rho=0.9)\n",
    "    elif opt == \"ADAM\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.99, amsgrad=False)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adadelta(learning_rate=learning_rate, rho=0.95)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,), kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
    "    \n",
    "    # Check Batch Normalization\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Check Dropout\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        validation_split=0.1)\n",
    "    \n",
    "    models[params] = model\n",
    "    histories[params] = history\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    scores[params] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp['text'].fillna('').values\n",
    "y = pd.get_dummies(yelp['stars']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "max_words = 3000\n",
    "maxlen = 400\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# For the LSTM, we are going to pad our sequences\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 10\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, amsgrad=False, clipvalue=.3)\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "lstm.add(SpatialDropout1D(0.2))\n",
    "lstm.add(Conv1D(64, 5, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "          bias_regularizer=regularizers.l2(1e-4)))\n",
    "lstm.add(MaxPooling1D(pool_size=4))\n",
    "lstm.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dense(5, activation='sigmoid'))\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = lstm.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM #1: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lstm.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save('./models/lstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. All Approach\n",
    "In the one vs. all approach, it goes by the following idea:\n",
    "- We will have $N$ learners for the multi-class classification problem, where $N$ is the number of classes\n",
    "- For each learner $L$, we will train $L$ on our training data $X_{Train}$ and $y_{Train}$. However, $y_{Train}$ consists of only one label, making it a binary classification problem instead of multinomial\n",
    "    - For instance, learner $L_1$ will still use all of $X_{Train}$, but $y_{Train}$ will now be transformed to be a binary vector $v_i$ where $i$ denotes the star rating we are attempting to predict\n",
    "- Once we have concluded our training, we will then create an ensemble model (bagging) that does the following\n",
    "    1. $L_1$, $L_2$, ..., $L_5$ all assign $p_i$ to each record in $X_{Test}$, where $p_i$ is the likelihood observation $x_n$ belongs to class $i$\n",
    "    2. From there, our prediction is the following: $P_n = argmax(p_1, p_2, p_3, p_4, p_5)$\n",
    "    \n",
    "After observing the challenge datasets 5 & 6, my partner and I believe this approach is a clever way to tackle the challenges while still having a strong model.\n",
    "\n",
    "Sources: https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/one-vs-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('cleaned_yelp_stemmed.csv')\n",
    "\n",
    "X = yelp['text'].fillna('').values\n",
    "y = pd.get_dummies(yelp['stars']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "max_words = 3000\n",
    "maxlen = 400\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stars = np.arange(1, 6)\n",
    "models = {}\n",
    "histories = {}\n",
    "batch_size = 1024\n",
    "epochs = 3\n",
    "\n",
    "for star in stars:\n",
    "    print(star)\n",
    "    y_train_sub = y_train[:, star - 1]\n",
    "    \n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, amsgrad=False, clipvalue=.3)\n",
    "\n",
    "    sub_lstm = Sequential()\n",
    "    sub_lstm.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "    sub_lstm.add(SpatialDropout1D(0.2))\n",
    "    sub_lstm.add(Conv1D(64, 5, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "              bias_regularizer=regularizers.l2(1e-4)))\n",
    "    sub_lstm.add(MaxPooling1D(pool_size=4))\n",
    "    sub_lstm.add(LSTM(128))\n",
    "    sub_lstm.add(BatchNormalization())\n",
    "    sub_lstm.add(Dense(8))\n",
    "    sub_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    sub_lstm.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = sub_lstm.fit(X_train, y_train_sub,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "    models[star] = sub_lstm\n",
    "    histories[star] = sub_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an ensemble model (maximization between learners) for all trained models\n",
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Evaluating the models above (TEST)\n",
    "y_test_und = pd.DataFrame(y_test)\n",
    "y_test_true = pd.DataFrame(y_test_und.columns[np.where(y_test_und!=0)[1]]) + 1\n",
    "\n",
    "# Unload models\n",
    "lstm_1, lstm_2, lstm_3, lstm_4, lstm_5 = models[1], models[2], models[3], models[4], models[5]\n",
    "\n",
    "## Predicting the probability for each observation each model\n",
    "print(\"Predicting 1 star\")\n",
    "one_star_ps = lstm_1.predict(X_test)\n",
    "print(\"Predicting 2 star\")\n",
    "two_star_ps = lstm_2.predict(X_test)\n",
    "print(\"Predicting 3 star\")\n",
    "three_star_ps = lstm_3.predict(X_test)\n",
    "print(\"Predicting 4 star\")\n",
    "four_star_ps = lstm_4.predict(X_test)\n",
    "print(\"Predicting 5 star\")\n",
    "five_star_ps = lstm_5.predict(X_test)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], y_test_true[0]))\n",
    "print(Accuracy(ps[\"pred\"], y_test_true[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1.save(\"./models/one_star.h5\")\n",
    "lstm_2.save(\"./models/two_star.h5\")\n",
    "lstm_3.save(\"./models/three_star.h5\")\n",
    "lstm_4.save(\"./models/four_star.h5\")\n",
    "lstm_5.save(\"./models/five_star.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373506,) (373506, 5)\n",
      "(160075,) (160075, 5)\n",
      "        1  2  3  4  5\n",
      "255947  0  0  0  0  1\n",
      "261035  0  0  0  0  1\n",
      "355633  0  0  0  0  1\n",
      "205506  0  0  0  0  1\n",
      "97222   0  0  0  1  0\n",
      "...    .. .. .. .. ..\n",
      "491832  0  0  0  0  1\n",
      "311959  0  0  0  0  1\n",
      "140524  1  0  0  0  0\n",
      "125037  0  0  1  0  0\n",
      "200135  0  0  0  1  0\n",
      "\n",
      "[160075 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "yelp = pd.read_csv('cleaned_yelp_stemmed.csv')\n",
    "\n",
    "X = yelp['text'].fillna('').values\n",
    "y = pd.get_dummies(yelp['stars'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "max_words = 3000\n",
    "maxlen = 400\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle) \n",
    "\n",
    "print(y_test)    \n",
    "\n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y_test.columns:\n",
    "        y_test[col] = 0\n",
    "        \n",
    "y_test = y_test[necc_cols]\n",
    "y_test = y_test.values\n",
    "\n",
    "X_baseline = tokenizer.texts_to_matrix(X_test)\n",
    "X_lstm = tokenizer.texts_to_sequences(X_test)\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanner\\Anaconda3\\envs\\yelp\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Trying our pretrained models\n",
    "# Optimizer\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=.001, decay_steps=10000, decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, amsgrad=False, clipvalue=.3)\n",
    "\n",
    "# Baseline\n",
    "baseline = load_model('./models/baseline.h5')\n",
    "\n",
    "baseline.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = load_model('./models/lstm.h5')\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# One vs. all\n",
    "lstm_1 = load_model('./models/one_star.h5')\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_2 = load_model('./models/two_star.h5')\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_3 = load_model('./models/three_star.h5')\n",
    "\n",
    "lstm_3.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_4 = load_model('./models/four_star.h5')\n",
    "\n",
    "lstm_4.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_5 = load_model('./models/five_star.h5')\n",
    "\n",
    "lstm_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1, 2, 3, 4, 5]\n",
    "# Baseline\n",
    "print(\"Baseline\")\n",
    "baseline_preds = pd.DataFrame(baseline.predict(X_baseline), columns=cols)\n",
    "baseline_preds['baseline_pred'] = baseline_preds.idxmax(axis=1)\n",
    "\n",
    "# LSTM\n",
    "print(\"LSTM\")\n",
    "lstm_preds = pd.DataFrame(lstm.predict(X_lstm), columns=cols)\n",
    "lstm_preds['lstm_pred'] = lstm_preds.idxmax(axis=1)\n",
    "\n",
    "# One vs. all\n",
    "print(\"OVA\")\n",
    "one_star_ps = lstm_1.predict(X_lstm)\n",
    "two_star_ps = lstm_2.predict(X_lstm)\n",
    "three_star_ps = lstm_3.predict(X_lstm)\n",
    "four_star_ps = lstm_4.predict(X_lstm)\n",
    "five_star_ps = lstm_5.predict(X_lstm)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "ova_preds = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ova_preds[\"ova_pred\"] = ova_preds.idxmax(axis=1)\n",
    "\n",
    "all_preds = pd.DataFrame([baseline_preds['baseline_pred'], lstm_preds['lstm_pred'], ova_preds['ova_pred']]).T\n",
    "all_preds[\"final_pred\"] = all_preds.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3103732625331876, 0.774218335155396]\n"
     ]
    }
   ],
   "source": [
    "print([MAE(all_preds[\"final_pred\"], pd.DataFrame(data=y_test, columns=cols).idxmax(axis=1)), Accuracy(all_preds[\"final_pred\"], pd.DataFrame(data=y_test, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "### Challenge 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = pd.read_json(\"./yelp_challenge_5_with_answers.jsonl\", lines = True)\n",
    "print(c5.shape)\n",
    "c5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(c5['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5['text'] = c5['text'].apply(clean_text)\n",
    "c5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load previous tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c5['text'].fillna('').values\n",
    "y = pd.get_dummies(c5['stars'])\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "max_words    \n",
    "    \n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X_baseline = tokenizer.texts_to_matrix(X)\n",
    "X_lstm = tokenizer.texts_to_sequences(X)\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "baseline = load_model('./models/baseline.h5')\n",
    "\n",
    "baseline.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = load_model('./models/lstm.h5')\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# One vs. all\n",
    "lstm_1 = load_model('./models/one_star.h5')\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_2 = load_model('./models/two_star.h5')\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_3 = load_model('./models/three_star.h5')\n",
    "\n",
    "lstm_3.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_4 = load_model('./models/four_star.h5')\n",
    "\n",
    "lstm_4.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_5 = load_model('./models/five_star.h5')\n",
    "\n",
    "lstm_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "print(baseline.evaluate(X_baseline, y))\n",
    "\n",
    "# LSTM\n",
    "print(lstm.evaluate(X_lstm, y))\n",
    "\n",
    "# One vs. All\n",
    "one_star_ps = lstm_1.predict(X_lstm)\n",
    "two_star_ps = lstm_2.predict(X_lstm)\n",
    "three_star_ps = lstm_3.predict(X_lstm)\n",
    "four_star_ps = lstm_4.predict(X_lstm)\n",
    "five_star_ps = lstm_5.predict(X_lstm)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"ova_pred\"] = ps.idxmax(axis=1)\n",
    "\n",
    "print([MAE(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attempt Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "baseline_preds = pd.DataFrame(baseline.predict(X_baseline), columns=cols)\n",
    "baseline_preds['baseline_pred'] = baseline_preds.idxmax(axis=1)\n",
    "\n",
    "# LSTM\n",
    "lstm_preds = pd.DataFrame(lstm.predict(X_lstm), columns=cols)\n",
    "lstm_preds['lstm_pred'] = lstm_preds.idxmax(axis=1)\n",
    "\n",
    "# One vs. all\n",
    "ova_preds = ps\n",
    "\n",
    "all_preds = pd.DataFrame([baseline_preds['baseline_pred'], lstm_preds['lstm_pred'], ova_preds['ova_pred']]).T\n",
    "all_preds[\"final_pred\"] = all_preds.mode(axis=1)[0]\n",
    "\n",
    "print([MAE(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(all_preds[\"final_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>Amazing for Trees\\n\\n$20 for a 5 gallon . I wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>How the hell can Taco Bell be closed before mi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>I actually had no intention of visiting this p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>Yesterday around 3:30 pm I was driving west on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>DR FITZMAURICE did surgery on both hands on th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                               text  stars\n",
       "0         60  Amazing for Trees\\n\\n$20 for a 5 gallon . I wi...      5\n",
       "1         61  How the hell can Taco Bell be closed before mi...      5\n",
       "2         62  I actually had no intention of visiting this p...      5\n",
       "3         63  Yesterday around 3:30 pm I was driving west on...      5\n",
       "4         64  DR FITZMAURICE did surgery on both hands on th...      5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c6 = pd.read_json(\"./yelp_challenge_6_with_answers.jsonl\", lines = True)\n",
    "print(c6.shape)\n",
    "c6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16cdcd08a88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(c6['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6['text'] = c6['text'].apply(clean_text)\n",
    "c6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load previous tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c6['text'].fillna('').values\n",
    "y = pd.get_dummies(c6['stars'])\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "max_words    \n",
    "    \n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X_baseline = tokenizer.texts_to_matrix(X)\n",
    "X_lstm = tokenizer.texts_to_sequences(X)\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "baseline = load_model('./models/baseline.h5')\n",
    "\n",
    "baseline.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = load_model('./models/lstm.h5')\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# One vs. all\n",
    "lstm_1 = load_model('./models/one_star.h5')\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_2 = load_model('./models/two_star.h5')\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_3 = load_model('./models/three_star.h5')\n",
    "\n",
    "lstm_3.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_4 = load_model('./models/four_star.h5')\n",
    "\n",
    "lstm_4.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_5 = load_model('./models/five_star.h5')\n",
    "\n",
    "lstm_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "print(baseline.evaluate(X_baseline, y))\n",
    "\n",
    "# LSTM\n",
    "print(lstm.evaluate(X_lstm, y))\n",
    "\n",
    "# One vs. All\n",
    "one_star_ps = lstm_1.predict(X_lstm)\n",
    "two_star_ps = lstm_2.predict(X_lstm)\n",
    "three_star_ps = lstm_3.predict(X_lstm)\n",
    "four_star_ps = lstm_4.predict(X_lstm)\n",
    "five_star_ps = lstm_5.predict(X_lstm)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"ova_pred\"] = ps.idxmax(axis=1)\n",
    "\n",
    "print([MAE(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attempt Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "baseline_preds = pd.DataFrame(baseline.predict(X_baseline), columns=cols)\n",
    "baseline_preds['baseline_pred'] = baseline_preds.idxmax(axis=1)\n",
    "\n",
    "# LSTM\n",
    "lstm_preds = pd.DataFrame(lstm.predict(X_lstm), columns=cols)\n",
    "lstm_preds['lstm_pred'] = lstm_preds.idxmax(axis=1)\n",
    "\n",
    "# One vs. all\n",
    "ova_preds = ps\n",
    "\n",
    "all_preds = pd.DataFrame([baseline_preds['baseline_pred'], lstm_preds['lstm_pred'], ova_preds['ova_pred']]).T\n",
    "all_preds[\"final_pred\"] = all_preds.mode(axis=1)[0]\n",
    "\n",
    "print([MAE(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(all_preds[\"final_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>We stopped here for lunch today and were pleas...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>We went for a quick lunch here - it's all reas...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Very bad food, avoid it. We were a group of 4 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Bring a friend or two to help open the door. I...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>Ukai serves some of the best sushi and sashimi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                               text  stars\n",
       "0         30  We stopped here for lunch today and were pleas...      4\n",
       "1         31  We went for a quick lunch here - it's all reas...      3\n",
       "2         32  Very bad food, avoid it. We were a group of 4 ...      2\n",
       "3         33  Bring a friend or two to help open the door. I...      3\n",
       "4         34  Ukai serves some of the best sushi and sashimi...      4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3 = pd.read_json(\"./yelp_challenge_3_with_answers.jsonl\", lines = True)\n",
    "print(c3.shape)\n",
    "c3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16ce1837b48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(c3['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>we stop here for lunch today and were pleasant...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>we went for a quick lunch here it s all reason...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>veri bad food avoid it we were a group of 4 an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>bring a friend or two to help open the door i ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>ukai serv some of the best sushi and sashimi i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                               text  stars\n",
       "0         30  we stop here for lunch today and were pleasant...      4\n",
       "1         31  we went for a quick lunch here it s all reason...      3\n",
       "2         32  veri bad food avoid it we were a group of 4 an...      2\n",
       "3         33  bring a friend or two to help open the door i ...      3\n",
       "4         34  ukai serv some of the best sushi and sashimi i...      4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3['text'] = c3['text'].apply(clean_text)\n",
    "c3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load previous tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c3['text'].fillna('').values\n",
    "y = pd.get_dummies(c3['stars'])\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "max_words    \n",
    "    \n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X_baseline = tokenizer.texts_to_matrix(X)\n",
    "X_lstm = tokenizer.texts_to_sequences(X)\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanner\\Anaconda3\\envs\\yelp\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "baseline = load_model('./models/baseline.h5')\n",
    "\n",
    "baseline.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = load_model('./models/lstm.h5')\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# One vs. all\n",
    "lstm_1 = load_model('./models/one_star.h5')\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_2 = load_model('./models/two_star.h5')\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_3 = load_model('./models/three_star.h5')\n",
    "\n",
    "lstm_3.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_4 = load_model('./models/four_star.h5')\n",
    "\n",
    "lstm_4.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_5 = load_model('./models/five_star.h5')\n",
    "\n",
    "lstm_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 0s 246us/step\n",
      "[1.1904090508986056, 0.5486891269683838]\n",
      "534/534 [==============================] - 0s 736us/step\n",
      "[0.9089857315302788, 0.5955055952072144]\n",
      "[0.6385767790262172, 0.49250936329588013]\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "print(baseline.evaluate(X_baseline, y))\n",
    "\n",
    "# LSTM\n",
    "print(lstm.evaluate(X_lstm, y))\n",
    "\n",
    "# One vs. All\n",
    "one_star_ps = lstm_1.predict(X_lstm)\n",
    "two_star_ps = lstm_2.predict(X_lstm)\n",
    "three_star_ps = lstm_3.predict(X_lstm)\n",
    "four_star_ps = lstm_4.predict(X_lstm)\n",
    "five_star_ps = lstm_5.predict(X_lstm)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"ova_pred\"] = ps.idxmax(axis=1)\n",
    "\n",
    "print([MAE(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attempt Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5131086142322098, 0.5674157303370787]\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "baseline_preds = pd.DataFrame(baseline.predict(X_baseline), columns=cols)\n",
    "baseline_preds['baseline_pred'] = baseline_preds.idxmax(axis=1)\n",
    "\n",
    "# LSTM\n",
    "lstm_preds = pd.DataFrame(lstm.predict(X_lstm), columns=cols)\n",
    "lstm_preds['lstm_pred'] = lstm_preds.idxmax(axis=1)\n",
    "\n",
    "# One vs. all\n",
    "ova_preds = ps\n",
    "\n",
    "all_preds = pd.DataFrame([baseline_preds['baseline_pred'], lstm_preds['lstm_pred'], ova_preds['ova_pred']]).T\n",
    "all_preds[\"final_pred\"] = all_preds.mode(axis=1)[0]\n",
    "\n",
    "print([MAE(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bd0fde548>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(all_preds[\"final_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qOOv-A-vo3kMT0yi4jIIlg</td>\n",
       "      <td>Not bad for fast food.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uqxkO6B6w_sIDSAGr0k_0A</td>\n",
       "      <td>Une institution du caf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0o_gGSU0m_4QyNLWEHKgug</td>\n",
       "      <td>J ai vraiment aim !!!!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BKAj-fKWW5G3yt3xAkbUCQ</td>\n",
       "      <td>They have good poutine.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fAhp8IwuGNT0ywKmsCs6VQ</td>\n",
       "      <td>Very old and dirty vans.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                      text  stars\n",
       "0  qOOv-A-vo3kMT0yi4jIIlg    Not bad for fast food.      4\n",
       "1  uqxkO6B6w_sIDSAGr0k_0A   Une institution du caf      4\n",
       "2  0o_gGSU0m_4QyNLWEHKgug   J ai vraiment aim !!!!      4\n",
       "3  BKAj-fKWW5G3yt3xAkbUCQ   They have good poutine.      4\n",
       "4  fAhp8IwuGNT0ywKmsCs6VQ  Very old and dirty vans.      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c8 = pd.read_json(\"./yelp_challenge_8_with_answers.jsonl\", lines = True)\n",
    "print(c8.shape)\n",
    "c8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16bca56d808>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(c8['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanner\\Anaconda3\\envs\\yelp\\lib\\site-packages\\bs4\\__init__.py:398: UserWarning: \"https://casetext.com/case/united-states-v-butterbaugh-2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  markup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qOOv-A-vo3kMT0yi4jIIlg</td>\n",
       "      <td>not bad for fast food</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uqxkO6B6w_sIDSAGr0k_0A</td>\n",
       "      <td>une institut du caf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0o_gGSU0m_4QyNLWEHKgug</td>\n",
       "      <td>j ai vraiment aim</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BKAj-fKWW5G3yt3xAkbUCQ</td>\n",
       "      <td>they have good poutin</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fAhp8IwuGNT0ywKmsCs6VQ</td>\n",
       "      <td>veri old and dirti van</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                    text  stars\n",
       "0  qOOv-A-vo3kMT0yi4jIIlg   not bad for fast food      4\n",
       "1  uqxkO6B6w_sIDSAGr0k_0A     une institut du caf      4\n",
       "2  0o_gGSU0m_4QyNLWEHKgug       j ai vraiment aim      4\n",
       "3  BKAj-fKWW5G3yt3xAkbUCQ   they have good poutin      4\n",
       "4  fAhp8IwuGNT0ywKmsCs6VQ  veri old and dirti van      1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c8['text'] = c8['text'].apply(clean_text)\n",
    "c8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load previous tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c8['text'].fillna('').values\n",
    "y = pd.get_dummies(c8['stars'])\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "max_words    \n",
    "    \n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X_baseline = tokenizer.texts_to_matrix(X)\n",
    "X_lstm = tokenizer.texts_to_sequences(X)\n",
    "X_lstm = pad_sequences(X_lstm, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanner\\Anaconda3\\envs\\yelp\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "baseline = load_model('./models/baseline.h5')\n",
    "\n",
    "baseline.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# LSTM\n",
    "lstm = load_model('./models/lstm.h5')\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# One vs. all\n",
    "lstm_1 = load_model('./models/one_star.h5')\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_2 = load_model('./models/two_star.h5')\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_3 = load_model('./models/three_star.h5')\n",
    "\n",
    "lstm_3.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_4 = load_model('./models/four_star.h5')\n",
    "\n",
    "lstm_4.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "lstm_5 = load_model('./models/five_star.h5')\n",
    "\n",
    "lstm_5.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 226us/step\n",
      "[1.0405480403900147, 0.6320000290870667]\n",
      "500/500 [==============================] - 0s 742us/step\n",
      "[0.8924245953559875, 0.6439999938011169]\n",
      "[0.616, 0.602]\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "print(baseline.evaluate(X_baseline, y))\n",
    "\n",
    "# LSTM\n",
    "print(lstm.evaluate(X_lstm, y))\n",
    "\n",
    "# One vs. All\n",
    "one_star_ps = lstm_1.predict(X_lstm)\n",
    "two_star_ps = lstm_2.predict(X_lstm)\n",
    "three_star_ps = lstm_3.predict(X_lstm)\n",
    "four_star_ps = lstm_4.predict(X_lstm)\n",
    "five_star_ps = lstm_5.predict(X_lstm)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"ova_pred\"] = ps.idxmax(axis=1)\n",
    "\n",
    "print([MAE(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(ps[\"ova_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attempt Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.566, 0.628]\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "baseline_preds = pd.DataFrame(baseline.predict(X_baseline), columns=cols)\n",
    "baseline_preds['baseline_pred'] = baseline_preds.idxmax(axis=1)\n",
    "\n",
    "# LSTM\n",
    "lstm_preds = pd.DataFrame(lstm.predict(X_lstm), columns=cols)\n",
    "lstm_preds['lstm_pred'] = lstm_preds.idxmax(axis=1)\n",
    "\n",
    "# One vs. all\n",
    "ova_preds = ps\n",
    "\n",
    "all_preds = pd.DataFrame([baseline_preds['baseline_pred'], lstm_preds['lstm_pred'], ova_preds['ova_pred']]).T\n",
    "all_preds[\"final_pred\"] = all_preds.mode(axis=1)[0]\n",
    "\n",
    "print([MAE(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)), Accuracy(all_preds[\"final_pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16b4415aac8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(all_preds[\"final_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
