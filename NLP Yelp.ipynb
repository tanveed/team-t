{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Yelp Review to Rating\n",
    "### Authors: Tanvee Desai and Tanner Arrizabalaga\n",
    "\n",
    "Hello! In this project, we will be looking over Yelp reviews (data available here: https://www.yelp.com/dataset) and utilizing ML/DL to accurately predict what the reviews star rating is based solely on text.\n",
    "\n",
    "This project is split into the following parts\n",
    "- Libraries\n",
    "- EDA\n",
    "- Data Cleaning\n",
    "    - Stop word removal, HTML parsing, punctuation removal, etc.\n",
    "    - Creation of a cleaned *and* stemmed dataset\n",
    "- Model Implementation\n",
    "    - Simple BOW Model Neural Network\n",
    "    - LSTM\n",
    "    - One vs. All LSTM Approach\n",
    "- Exploring Challenges\n",
    "    - Challenge 5\n",
    "    - Challenge 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# ML/DL\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Conv1D, MaxPooling1D, LSTM, BatchNormalization, SpatialDropout1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_json(\"./yelp_review_training_dataset.jsonl\", lines = True)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - Stars\n",
    "Not too much to go off of, but let's get a general understanding of our data. How many nulls do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(yelp['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can potentially look at is whether or not the reviews are balanced. Let's say >=4 is positive, and <4 is negative. If we do see a significant difference in positive and negative reviews, we can balance it before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg(x):\n",
    "    if x >= 4:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "    \n",
    "yelp['category'] = yelp['stars'].apply(pos_or_neg)\n",
    "\n",
    "sns.countplot(yelp['category'])\n",
    "num_pos = np.count_nonzero(yelp['category'] == 'Positive')\n",
    "num_neg = np.count_nonzero(yelp['category'] == 'Negative')\n",
    "print(\"Positive to negative review ratio: \", num_pos / num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 1 and 2/3 times as many positive reviews as negative reviews. We will first try no class balancing when building the model, but may turn to class balancing later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to run the bottom two \n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "   \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    text = ' '.join(ps.stem(word) for word in text.split() if word not in STOPWORDS) # delete stopwords from text and stem\n",
    "    return text\n",
    "    \n",
    "# yelp['text'] = yelp['text'].apply(clean_text)\n",
    "# yelp.to_csv('cleaned_yelp_stemmed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "#### 1. Average Star Error (Average Absolute offset between predicted and true number of stars)\n",
    "#### 2. Accuracy (Exact Match -- Number of exactly predicted star ratings / total samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):\n",
    "    diffs = np.abs(y_true - y_pred)\n",
    "    loss = np.mean(diffs)\n",
    "    return loss\n",
    "\n",
    "def Accuracy(y_true, y_pred):\n",
    "    correct = y_true == y_pred\n",
    "    cor_count = np.count_nonzero(correct)\n",
    "    return cor_count / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split (Unbalanced and balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('cleaned_yelp_stemmed.csv')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp['text'].fillna('').values\n",
    "y = yelp['stars']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "tokenize.fit_on_texts(X_train)\n",
    "X_train = tokenize.texts_to_matrix(X_train)\n",
    "X_test = tokenize.texts_to_matrix(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are computing a single model, but in future we will optimize on several parameters, listed below\n",
    "* Batch size\n",
    "* Learning rate\n",
    "* Gradient clipping\n",
    "* Drop out\n",
    "* Batch normalization\n",
    "* Optimizers\n",
    "* Regularization\n",
    "\n",
    "After some tests, the main variations I noticed were from the learning rate, regularization, and the choice of the optimizer. With that being said, this baseline model will use **ADAM with a learning rate of .0001 and regularization (kernel, bias, and activity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 20\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.95, amsgrad=False)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,), kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "          bias_regularizer=regularizers.l2(1e-4),\n",
    "          activity_regularizer=regularizers.l2(1e-5)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now training with several parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "batch_sizes = [128, 256, 512]\n",
    "epochs = [5]\n",
    "learning_rates = [.01, .001, .0001]\n",
    "dropout = [False, True]\n",
    "batch_norm = [False, True]\n",
    "regularization = [True]\n",
    "optimizers = [\"SGD\", \"RMSProp\", \"ADAM\"]\n",
    "\n",
    "all_lists = [batch_sizes, epochs, learning_rates, dropout, batch_norm, regularization, optimizers]\n",
    "\n",
    "params_to_test = list(itertools.product(*all_lists))\n",
    "print(len(params_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "histories = {}\n",
    "scores = {}\n",
    "\n",
    "for params in params_to_test:\n",
    "    print(params)\n",
    "    batch_size, epochs, learning_rate, dropout, batch_norm, regularization, opt = params\n",
    "    \n",
    "    if opt == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0, nesterov=False)\n",
    "    elif opt == \"RMSProp\":\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate, rho=0.9)\n",
    "    elif opt == \"ADAM\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.99, amsgrad=False)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adadelta(learning_rate=learning_rate, rho=0.95)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(max_words,), kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
    "    \n",
    "    # Check Batch Normalization\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Check Dropout\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        validation_split=0.1)\n",
    "    \n",
    "    models[params] = model\n",
    "    histories[params] = history\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "    print(score)\n",
    "    \n",
    "    scores[params] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = yelp['text'].fillna('').values\n",
    "y = pd.get_dummies(yelp['stars']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "max_words = 3000\n",
    "maxlen = 400\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "epochs = 5\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, amsgrad=False, clipvalue=.3)\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "lstm.add(SpatialDropout1D(0.2))\n",
    "lstm.add(Conv1D(64, 5, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "          bias_regularizer=regularizers.l2(1e-4)))\n",
    "lstm.add(MaxPooling1D(pool_size=4))\n",
    "lstm.add(LSTM(128))\n",
    "lstm.add(BatchNormalization())\n",
    "lstm.add(Dense(5, activation='sigmoid'))\n",
    "lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = lstm.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM #1: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lstm.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. All Approach\n",
    "In the one vs. all approach, it goes by the following idea:\n",
    "- We will have $N$ learners for the multi-class classification problem, where $N$ is the number of classes\n",
    "- For each learner $L$, we will train $L$ on our training data $X_{Train}$ and $y_{Train}$. However, $y_{Train}$ consists of only one label, making it a binary classification problem instead of multinomial\n",
    "    - For instance, learner $L_1$ will still use all of $X_{Train}$, but $y_{Train}$ will now be transformed to be a binary vector $v_i$ where $i$ denotes the star rating we are attempting to predict\n",
    "- Once we have concluded our training, we will then create an ensemble model (bagging) that does the following\n",
    "    1. $L_1$, $L_2$, ..., $L_5$ all assign $p_i$ to each record in $X_{Test}$, where $p_i$ is the likelihood observation $x_n$ belongs to class $i$\n",
    "    2. From there, our prediction is the following: $P_n = argmax(p_1, p_2, p_3, p_4, p_5)$\n",
    "    \n",
    "After observing the challenge datasets 5 & 6, my partner and I believe this approach is a clever way to tackle the challenges while still having a strong model.\n",
    "\n",
    "Sources: https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/one-vs-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('cleaned_yelp_stemmed.csv')\n",
    "\n",
    "X = yelp['text'].fillna('').values\n",
    "y = pd.get_dummies(yelp['stars']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "max_words = 3000\n",
    "maxlen = 400\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stars = np.arange(1, 6)\n",
    "models = {}\n",
    "histories = {}\n",
    "batch_size = 1024\n",
    "epochs = 3\n",
    "\n",
    "for star in stars:\n",
    "    print(star)\n",
    "    y_train_sub = y_train[:, star - 1]\n",
    "    \n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, amsgrad=False, clipvalue=.3)\n",
    "\n",
    "    sub_lstm = Sequential()\n",
    "    sub_lstm.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "    sub_lstm.add(SpatialDropout1D(0.2))\n",
    "    sub_lstm.add(Conv1D(64, 5, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "              bias_regularizer=regularizers.l2(1e-4)))\n",
    "    sub_lstm.add(MaxPooling1D(pool_size=4))\n",
    "    sub_lstm.add(LSTM(128))\n",
    "    sub_lstm.add(BatchNormalization())\n",
    "    sub_lstm.add(Dense(8))\n",
    "    sub_lstm.add(Dense(1, activation='sigmoid'))\n",
    "    sub_lstm.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = sub_lstm.fit(X_train, y_train_sub,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "    models[star] = sub_lstm\n",
    "    histories[star] = sub_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an ensemble model (maximization between learners) for all trained models\n",
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the models above (TRAIN)\n",
    "y_train_und = pd.DataFrame(y_train)\n",
    "y_train_true = pd.DataFrame(y_train_und.columns[np.where(y_train_und!=0)[1]]) + 1\n",
    "\n",
    "# Unload models\n",
    "lstm_1, lstm_2, lstm_3, lstm_4, lstm_5 = models[1], models[2], models[3], models[4], models[5]\n",
    "\n",
    "## Predicting the probability for each observation each model\n",
    "one_star_ps = lstm_1.predict(X_train)\n",
    "two_star_ps = lstm_2.predict(X_train)\n",
    "three_star_ps = lstm_3.predict(X_train)\n",
    "four_star_ps = lstm_4.predict(X_train)\n",
    "five_star_ps = lstm_5.predict(X_train)\n",
    "\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], y_train_true[0]))\n",
    "print(Accuracy(ps[\"pred\"], y_train_true[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the models above (TEST)\n",
    "y_test_und = pd.DataFrame(y_test)\n",
    "y_test_true = pd.DataFrame(y_test_und.columns[np.where(y_test_und!=0)[1]]) + 1\n",
    "\n",
    "# Unload models\n",
    "lstm_1, lstm_2, lstm_3, lstm_4, lstm_5 = models[1], models[2], models[3], models[4], models[5]\n",
    "\n",
    "## Predicting the probability for each observation each model\n",
    "one_star_ps = lstm_1.predict(X_test)\n",
    "two_star_ps = lstm_2.predict(X_test)\n",
    "three_star_ps = lstm_3.predict(X_test)\n",
    "four_star_ps = lstm_4.predict(X_test)\n",
    "five_star_ps = lstm_5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T\n",
    "\n",
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], y_test_true[0]))\n",
    "print(Accuracy(ps[\"pred\"], y_test_true[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lstm_1.save(\"one_star.h5\")\n",
    "lstm_2.save(\"two_star.h5\")\n",
    "lstm_3.save(\"three_star.h5\")\n",
    "lstm_4.save(\"four_star.h5\")\n",
    "lstm_5.save(\"five_star.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "#### Challenge 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = pd.read_json(\"./yelp_challenge_5_with_answers.jsonl\", lines = True)\n",
    "print(c5.shape)\n",
    "c5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(c5['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "   \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    text = ' '.join(ps.stem(word) for word in text.split() if word not in STOPWORDS) # delete stopwords from text and stem\n",
    "    return text\n",
    "    \n",
    "c5['text'] = c5['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c5['text'].fillna('').values\n",
    "y = pd.get_dummies(c5['stars'])\n",
    "\n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.summary()\n",
    "# score = lstm.evaluate(X, y,\n",
    "#                        batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=y_pred, columns=cols)\n",
    "\n",
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))\n",
    "print(Accuracy(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(ps[\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One vs. All Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lstm_1 = load_model('one_star.h5')\n",
    "lstm_2 = load_model('two_star.h5')\n",
    "lstm_3 = load_model('three_star.h5')\n",
    "lstm_4 = load_model('four_star.h5')\n",
    "lstm_5 = load_model('five_star.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_ps = lstm_1.predict(X)\n",
    "two_star_ps = lstm_2.predict(X)\n",
    "three_star_ps = lstm_3.predict(X)\n",
    "four_star_ps = lstm_4.predict(X)\n",
    "five_star_ps = lstm_5.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_probs = pd.DataFrame([one_star_ps, two_star_ps], columns = [1, 2])\n",
    "# train_probs\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))\n",
    "print(Accuracy(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(ps[\"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "#### Challenge 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6 = pd.read_json(\"./yelp_challenge_6_with_answers.jsonl\", lines = True)\n",
    "print(c6.shape)\n",
    "c6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(c6['stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "   \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    text = ' '.join(ps.stem(word) for word in text.split() if word not in STOPWORDS) # delete stopwords from text and stem\n",
    "    return text\n",
    "    \n",
    "c6['text'] = c6['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c6['text'].fillna('').values\n",
    "y = pd.get_dummies(c6['stars'])\n",
    "\n",
    "necc_cols = [1, 2, 3, 4, 5]\n",
    "for col in necc_cols:\n",
    "    if col not in y.columns:\n",
    "        y[col] = 0\n",
    "        \n",
    "y = y[necc_cols]\n",
    "y = y.values\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lstm.evaluate(X, y,batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=y_pred, columns=cols)\n",
    "\n",
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))\n",
    "print(Accuracy(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One vs. All Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "lstm_1 = load_model('one_star.h5')\n",
    "lstm_2 = load_model('two_star.h5')\n",
    "lstm_3 = load_model('three_star.h5')\n",
    "lstm_4 = load_model('four_star.h5')\n",
    "lstm_5 = load_model('five_star.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_ps = lstm_1.predict(X)\n",
    "two_star_ps = lstm_2.predict(X)\n",
    "three_star_ps = lstm_3.predict(X)\n",
    "four_star_ps = lstm_4.predict(X)\n",
    "five_star_ps = lstm_5.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_probs = pd.DataFrame([one_star_ps, two_star_ps], columns = [1, 2])\n",
    "# train_probs\n",
    "data = [one_star_ps.flatten(), two_star_ps.flatten(), three_star_ps.flatten(), four_star_ps.flatten(), five_star_ps.flatten()]\n",
    "cols = [1, 2, 3, 4, 5]\n",
    "ps = pd.DataFrame(data=data, index=cols).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps[\"pred\"] = ps.idxmax(axis=1)\n",
    "ps.head()\n",
    "\n",
    "print(MAE(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))\n",
    "print(Accuracy(ps[\"pred\"], pd.DataFrame(data=y, columns=cols).idxmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(ps[\"pred\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
